#!/usr/bin/env python3
"""
å¿«é€Ÿè®­ç»ƒæµ‹è¯•ï¼šéªŒè¯paddingæ–¹æ¡ˆæ˜¯å¦èƒ½è®©è®­ç»ƒæ­£å¸¸å¯åŠ¨
åªè¿è¡Œå‡ ä¸ªè®­ç»ƒæ­¥éª¤ï¼Œä¸»è¦éªŒè¯tensorç»´åº¦å…¼å®¹æ€§
"""

import os
import sys
import torch
import logging
from datetime import datetime
from pathlib import Path

def setup_logging():
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = f"./logs/quick_train_test_{timestamp}.log"

    Path("./logs").mkdir(exist_ok=True)

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, mode='w'),
            logging.StreamHandler(sys.stdout)
        ]
    )

    logger = logging.getLogger(__name__)
    logger.info(f"Quick train test log: {log_file}")
    return logger

def main():
    logger = setup_logging()

    logger.info("ğŸš€ å¿«é€Ÿè®­ç»ƒæµ‹è¯• - éªŒè¯Paddingæ–¹æ¡ˆ")
    logger.info("="*60)

    # è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨wandb
    os.environ["WANDB_DISABLED"] = "true"
    os.environ["WANDB_MODE"] = "disabled"

    # è®¾ç½®è·¯å¾„
    project_root = Path(__file__).parent
    sys.path.append(str(project_root))

    try:
        # å¯¼å…¥æ¨¡å—
        from qwenvl.train.argument import ModelArguments, DataArguments, TrainingArguments
        from qwenvl.data.data_qwen import make_supervised_data_module
        from transformers import (
            Qwen2_5_VLForConditionalGeneration,
            AutoTokenizer,
            AutoProcessor,
            Trainer
        )

        logger.info("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")

        # é…ç½®å‚æ•°ï¼ˆæœ€å°é…ç½®ï¼‰
        model_args = ModelArguments(
            model_name_or_path="./models/Qwen2.5-VL-7B-Instruct",
            version="qwen",
            freeze_backbone=False,
            tune_mm_mlp_adapter=True,
        )

        data_args = DataArguments(
            data_path="./data/datasets_grounding",
            lazy_preprocess=True,
            is_multimodal=True,
            image_folder="./data/images",
            max_pixels=448*448,  # å›ºå®šåˆ°å®‰å…¨å°ºå¯¸
            min_pixels=448*448,  # å›ºå®šå°ºå¯¸ï¼Œé¿å…å˜åŒ–
            dataset_use="curve_detection_high",  # åªç”¨ä¸€ä¸ªå°æ•°æ®é›†
            data_flatten=False,
            model_type="qwen2.5vl",
            enable_spatial_merge_compatibility=False  # ä½¿ç”¨paddingæ–¹æ¡ˆ
        )

        training_args = TrainingArguments(
            output_dir="./quick_test_output",
            per_device_train_batch_size=1,
            gradient_accumulation_steps=1,
            max_steps=3,  # åªè¿è¡Œ3æ­¥
            learning_rate=1e-6,
            logging_steps=1,
            save_steps=999999,  # ä¸ä¿å­˜
            model_max_length=2048,
            bf16=True,
            dataloader_num_workers=0,
            remove_unused_columns=False,
            # ç¦ç”¨æ‰€æœ‰å¤–éƒ¨æ—¥å¿—å’ŒæŠ¥å‘Š
            report_to=[],  # ç¦ç”¨wandbç­‰æ‰€æœ‰æŠ¥å‘Š
            logging_dir=None,  # ç¦ç”¨tensorboard
            run_name="quick_test",  # è®¾ç½®è¿è¡Œåç§°é¿å…å†²çª
        )

        logger.info("âœ… å‚æ•°é…ç½®å®Œæˆ")

        # åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
        logger.info("åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨...")

        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            model_args.model_name_or_path,
            torch_dtype=torch.bfloat16,
            device_map="auto"
        )
        logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

        tokenizer = AutoTokenizer.from_pretrained(
            model_args.model_name_or_path,
            model_max_length=training_args.model_max_length,
            padding_side="right",
            use_fast=False,
        )
        logger.info("âœ… TokenizeråŠ è½½æˆåŠŸ")

        processor = AutoProcessor.from_pretrained(model_args.model_name_or_path, use_fast=False)
        data_args.image_processor = processor.image_processor
        data_args.image_processor.max_pixels = data_args.max_pixels
        data_args.image_processor.min_pixels = data_args.min_pixels
        logger.info("âœ… ProcessoråŠ è½½æˆåŠŸ")

        # åˆ›å»ºæ•°æ®æ¨¡å—
        logger.info("åˆ›å»ºæ•°æ®æ¨¡å—...")
        data_module = make_supervised_data_module(
            tokenizer=tokenizer,
            data_args=data_args
        )

        train_dataset = data_module['train_dataset']
        logger.info(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œå¤§å°: {len(train_dataset)}")

        # æµ‹è¯•åŠ è½½ä¸€ä¸ªæ ·æœ¬
        logger.info("æµ‹è¯•æ•°æ®åŠ è½½...")
        sample = train_dataset[0]
        logger.info("âœ… æ ·æœ¬åŠ è½½æˆåŠŸ")

        if 'pixel_values' in sample:
            logger.info(f"Pixel values shape: {sample['pixel_values'].shape}")
        if 'image_grid_thw' in sample:
            logger.info(f"Grid THW: {sample['image_grid_thw']}")

        # åˆ›å»ºtrainer
        logger.info("åˆ›å»ºTrainer...")
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            data_collator=data_module['data_collator'],
        )
        logger.info("âœ… Traineråˆ›å»ºæˆåŠŸ")

        # å¼€å§‹è®­ç»ƒï¼ˆåªè¿è¡Œå‡ æ­¥ï¼‰
        logger.info("å¼€å§‹å¿«é€Ÿè®­ç»ƒæµ‹è¯•...")
        logger.info("æ³¨æ„ï¼šè¿™åªæ˜¯éªŒè¯tensorç»´åº¦å…¼å®¹æ€§ï¼Œä¸æ˜¯å®Œæ•´è®­ç»ƒ")
        logger.info("å·²ç¦ç”¨wandbå’Œæ‰€æœ‰å¤–éƒ¨æ—¥å¿—")

        try:
            trainer.train()
            logger.info("ğŸ‰ è®­ç»ƒæµ‹è¯•æˆåŠŸï¼æ²¡æœ‰tensorç»´åº¦é”™è¯¯")
            logger.info("âœ… Paddingæ–¹æ¡ˆå®Œå…¨è§£å†³äº†spatial_mergeé—®é¢˜")
            logger.info("âœ… å¯ä»¥å®‰å…¨è¿è¡Œå®Œæ•´è®­ç»ƒäº†")
            return True

        except RuntimeError as e:
            if "shape" in str(e) and "invalid for input of size" in str(e):
                logger.error(f"âŒ ä»ç„¶å­˜åœ¨tensorç»´åº¦é—®é¢˜: {e}")
                return False
            else:
                logger.error(f"âŒ å…¶ä»–è®­ç»ƒé”™è¯¯: {e}")
                # æ‰“å°æ›´å¤šé”™è¯¯ä¿¡æ¯å¸®åŠ©è°ƒè¯•
                import traceback
                logger.error("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
                logger.error(traceback.format_exc())
                return False

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ å¿«é€Ÿè®­ç»ƒæµ‹è¯•æˆåŠŸï¼å¯ä»¥è¿è¡Œå®Œæ•´è®­ç»ƒäº†")
        print("å»ºè®®è¿è¡Œ: python train.py")
    else:
        print("\nğŸ’¥ å¿«é€Ÿè®­ç»ƒæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")

    sys.exit(0 if success else 1)