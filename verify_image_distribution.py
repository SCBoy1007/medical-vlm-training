#!/usr/bin/env python3
"""
éªŒè¯è„šæœ¬ï¼šæ£€æŸ¥æ¯å¼ å›¾ç‰‡åœ¨JSONæ–‡ä»¶ä¸­çš„åˆ†å¸ƒæ¨¡å¼
é¢„æœŸï¼šè¦ä¹ˆå‡ºç°åœ¨æ‰€æœ‰9ä¸ªç›¸å…³JSONæ–‡ä»¶ä¸­ï¼Œè¦ä¹ˆä¸å‡ºç°ï¼ˆæ­£å¸¸è„Šæ¤ï¼‰
"""

import json
import re
from pathlib import Path
from collections import defaultdict

# è·¯å¾„é…ç½®
DATA_ROOT = "/mnt/c/Users/HKUBS/OneDrive/æ¡Œé¢/LLM_Study/medical_vlm_training/data"
REFERENCE_JSON_DIR = "/mnt/c/Users/HKUBS/OneDrive/æ¡Œé¢/LLM_Study/aasce/02_data_analysis/quality_stratification/json"

# ç”Ÿæˆæ‰€æœ‰ç›¸å…³çš„JSONæ–‡ä»¶åˆ—è¡¨ï¼ˆåŒ…å«bboxçš„groundingå’Œtext_groundingæ•°æ®é›†ï¼‰
def get_all_bbox_json_files():
    """åŠ¨æ€ç”Ÿæˆæ‰€æœ‰åŒ…å«bboxçš„JSONæ–‡ä»¶è·¯å¾„"""
    files = []

    # 3ä¸ªå¤‡ä»½æ–‡ä»¶
    tasks = ["apex_vertebrae", "curve_detection", "end_vertebrae"]
    for task in tasks:
        files.append(f"datasets_grounding/{task}/{task}_dataset_grounding_backup.json")

    # grounding åˆ†å‰²æ–‡ä»¶ (train/test/val Ã— high/low quality)
    splits = ["train", "test", "val"]
    qualities = ["high_quality", "low_quality"]

    for task in tasks:
        for split in splits:
            for quality in qualities:
                files.append(f"datasets_grounding/{task}/{split}_{quality}/{task}_{split}_{quality}_grounding.json")

    # text_grounding åˆ†å‰²æ–‡ä»¶ (train/test/val Ã— high/low quality)
    for task in tasks:
        for split in splits:
            for quality in qualities:
                files.append(f"datasets_text_grounding/{task}/{split}_{quality}/{task}_{split}_{quality}_text_grounding.json")

    return files

BBOX_JSON_FILES = get_all_bbox_json_files()

def get_reference_image_info():
    """ä»å‚è€ƒJSONç›®å½•è·å–æ‰€æœ‰å›¾ç‰‡çš„å°ºå¯¸ä¿¡æ¯"""
    reference_images = {}

    json_dir = Path(REFERENCE_JSON_DIR)

    for json_file in json_dir.glob("*_curves.json"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if 'curves' in data and len(data['curves']) > 0:
                # ä»æ–‡ä»¶åæ¨æ–­å›¾ç‰‡å
                base_name = json_file.stem.replace('_curves', '')
                image_name = base_name + '.jpg'

                # è·å–resizeä¿¡æ¯
                resize_info = data['curves'][0].get('resize_info')
                if resize_info:
                    reference_images[image_name] = {
                        'original_size': resize_info['original_size'],
                        'smart_resize_size': resize_info['resized_size'],
                        'curve_count': len(data['curves'])
                    }

        except Exception as e:
            print(f"Warning: Could not parse {json_file}: {e}")

    return reference_images

def extract_images_from_json(file_path):
    """ä»JSONæ–‡ä»¶ä¸­æå–æ‰€æœ‰å›¾ç‰‡åç§°"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        images = set()

        # å¤„ç†ä¸åŒçš„JSONæ ¼å¼
        if isinstance(data, list):
            # åˆ—è¡¨æ ¼å¼
            for item in data:
                if 'image' in item:
                    image_path = item['image']
                    # æå–æ–‡ä»¶å
                    image_name = Path(image_path).name
                    images.add(image_name)
        elif isinstance(data, dict):
            # å­—å…¸æ ¼å¼ï¼Œå¯èƒ½æœ‰annotationså­—æ®µ
            if 'annotations' in data:
                for image_name, item in data['annotations'].items():
                    images.add(image_name)

        return images

    except Exception as e:
        print(f"Warning: Could not parse {file_path}: {e}")
        return set()

def count_bbox_in_file(file_path, image_name):
    """è®¡ç®—æŒ‡å®šå›¾ç‰‡åœ¨æ–‡ä»¶ä¸­çš„bboxæ•°é‡"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # ç®€å•è®¡æ•°ï¼šåœ¨å›¾ç‰‡ä¸Šä¸‹æ–‡ä¸­çš„bbox_2då‡ºç°æ¬¡æ•°
        lines = content.split('\n')
        in_target_context = False
        bbox_count = 0

        for line in lines:
            if image_name in line:
                in_target_context = True
                continue

            if in_target_context:
                # æ£€æŸ¥æ˜¯å¦åˆ°äº†æ–°å›¾ç‰‡
                if '"image"' in line and image_name not in line:
                    break

                # è®¡ç®—è¿™è¡Œçš„bbox_2dæ•°é‡
                bbox_count += len(re.findall(r'bbox_2d.*?\[\d+,\s*\d+,\s*\d+,\s*\d+\]', line))

        return bbox_count

    except Exception as e:
        print(f"Warning: Could not count bboxes in {file_path}: {e}")
        return 0

def main():
    print("=" * 80)
    print("å›¾ç‰‡åˆ†å¸ƒæ¨¡å¼éªŒè¯ (å®Œæ•´ç‰ˆ)")
    print("=" * 80)
    print(f"æ€»å…±æ£€æŸ¥ {len(BBOX_JSON_FILES)} ä¸ªJSONæ–‡ä»¶:")
    for i, file in enumerate(BBOX_JSON_FILES, 1):
        print(f"  {i:2d}. {file}")
    print()

    # 1. è·å–å‚è€ƒå›¾ç‰‡ä¿¡æ¯
    print("ğŸ“Š Step 1: è·å–å‚è€ƒå›¾ç‰‡ä¿¡æ¯...")
    reference_images = get_reference_image_info()
    print(f"   ä»å‚è€ƒJSONæ‰¾åˆ° {len(reference_images)} å¼ æœ‰å¼¯æ›²æ ‡æ³¨çš„å›¾ç‰‡")

    # 2. æ”¶é›†æ¯ä¸ªJSONæ–‡ä»¶ä¸­çš„å›¾ç‰‡
    print("\nğŸ“Š Step 2: æ”¶é›†å„JSONæ–‡ä»¶ä¸­çš„å›¾ç‰‡...")
    image_distribution = defaultdict(list)

    for json_file in BBOX_JSON_FILES:
        file_path = Path(DATA_ROOT) / json_file
        if file_path.exists():
            images = extract_images_from_json(str(file_path))
            print(f"   {json_file}: {len(images)} å¼ å›¾ç‰‡")

            for image in images:
                image_distribution[image].append(json_file)
        else:
            print(f"   âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")

    # 3. åˆ†æåˆ†å¸ƒæ¨¡å¼
    print(f"\nğŸ“Š Step 3: åˆ†æåˆ†å¸ƒæ¨¡å¼...")

    pattern_0 = []  # ä¸å‡ºç°åœ¨ä»»ä½•æ–‡ä»¶ä¸­
    pattern_9 = []  # å‡ºç°åœ¨æ‰€æœ‰9ä¸ªæ–‡ä»¶ä¸­
    pattern_other = []  # å…¶ä»–å¼‚å¸¸æ¨¡å¼

    total_expected_files = len(BBOX_JSON_FILES)

    for image, files in image_distribution.items():
        file_count = len(files)

        if file_count == 0:
            pattern_0.append(image)
        elif file_count == total_expected_files:
            pattern_9.append(image)
        else:
            pattern_other.append((image, file_count, files))

    # 4. æ£€æŸ¥å‚è€ƒå›¾ç‰‡æ˜¯å¦éƒ½éµå¾ªpattern_9
    print(f"\nğŸ“Š Step 4: éªŒè¯å‚è€ƒå›¾ç‰‡åˆ†å¸ƒ...")
    reference_not_in_pattern_9 = []

    for ref_image in reference_images.keys():
        if ref_image not in pattern_9:
            current_count = len(image_distribution.get(ref_image, []))
            reference_not_in_pattern_9.append((ref_image, current_count))

    # 5. è¾“å‡ºç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š åˆ†å¸ƒæ¨¡å¼åˆ†æç»“æœ:")
    print("=" * 80)

    print(f"âœ… Pattern 9 (å‡ºç°åœ¨æ‰€æœ‰{total_expected_files}ä¸ªæ–‡ä»¶): {len(pattern_9)} å¼ å›¾ç‰‡")
    if len(pattern_9) <= 10:  # å¦‚æœä¸å¤šå°±å…¨éƒ¨æ˜¾ç¤º
        for img in pattern_9:
            print(f"     {img}")
    else:
        for img in pattern_9[:5]:
            print(f"     {img}")
        print(f"     ... è¿˜æœ‰ {len(pattern_9)-5} å¼ å›¾ç‰‡")

    print(f"\nâœ… Pattern 0 (ä¸å‡ºç°åœ¨ä»»ä½•æ–‡ä»¶): {len(pattern_0)} å¼ å›¾ç‰‡")

    print(f"\nâŒ å¼‚å¸¸æ¨¡å¼ (éƒ¨åˆ†å‡ºç°): {len(pattern_other)} å¼ å›¾ç‰‡")
    for img, count, files in pattern_other:
        print(f"     {img}: å‡ºç°åœ¨ {count} ä¸ªæ–‡ä»¶ä¸­")
        for file in files[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªæ–‡ä»¶
            print(f"       - {file}")
        if len(files) > 3:
            print(f"       - ... è¿˜æœ‰ {len(files)-3} ä¸ªæ–‡ä»¶")

    print(f"\nğŸ” å‚è€ƒå›¾ç‰‡éªŒè¯:")
    print(f"   å‚è€ƒJSONä¸­æœ‰å¼¯æ›²çš„å›¾ç‰‡: {len(reference_images)}")
    print(f"   éµå¾ªPattern 9çš„å‚è€ƒå›¾ç‰‡: {len(reference_images) - len(reference_not_in_pattern_9)}")

    if reference_not_in_pattern_9:
        print(f"   âŒ ä¸éµå¾ªPattern 9çš„å‚è€ƒå›¾ç‰‡: {len(reference_not_in_pattern_9)}")
        for img, count in reference_not_in_pattern_9:
            print(f"      {img}: åªå‡ºç°åœ¨ {count} ä¸ªæ–‡ä»¶ä¸­")

    # 6. æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š æ€»ç»“:")
    all_good = len(pattern_other) == 0 and len(reference_not_in_pattern_9) == 0

    if all_good:
        print("âœ… åˆ†å¸ƒæ¨¡å¼å®Œå…¨ç¬¦åˆé¢„æœŸï¼")
        print(f"   - {len(pattern_9)} å¼ æœ‰ç—…ä¾‹å›¾ç‰‡å‡ºç°åœ¨æ‰€æœ‰ {total_expected_files} ä¸ªæ–‡ä»¶ä¸­")
        print(f"   - {len(pattern_0)} å¼ æ­£å¸¸å›¾ç‰‡ä¸å‡ºç°åœ¨ä»»ä½•bboxæ–‡ä»¶ä¸­")
    else:
        print("âŒ å‘ç°å¼‚å¸¸åˆ†å¸ƒæ¨¡å¼ï¼Œéœ€è¦æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§")

    print("=" * 80)

if __name__ == "__main__":
    main()