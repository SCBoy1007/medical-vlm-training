#!/usr/bin/env python3
"""
æ‰¹é‡å¤„ç†è„šæœ¬ï¼šå°†æ‰€æœ‰å›¾ç‰‡resizeåˆ°700x1400å¹¶æ›´æ–°JSONä¸­çš„bboxåæ ‡
"""

import json
import re
import os
from pathlib import Path
from PIL import Image
from collections import defaultdict
import traceback

# ç›®æ ‡å°ºå¯¸
TARGET_SIZE = (700, 1400)  # width, height

# è·¯å¾„é…ç½®
DATA_ROOT = "/mnt/c/Users/HKUBS/OneDrive/æ¡Œé¢/LLM_Study/medical_vlm_training/data"
REFERENCE_JSON_DIR = "/mnt/c/Users/HKUBS/OneDrive/æ¡Œé¢/LLM_Study/aasce/02_data_analysis/quality_stratification/json"

def get_all_bbox_json_files():
    """è·å–æ‰€æœ‰åŒ…å«bboxçš„JSONæ–‡ä»¶è·¯å¾„"""
    files = []

    # 3ä¸ªå¤‡ä»½æ–‡ä»¶
    tasks = ["apex_vertebrae", "curve_detection", "end_vertebrae"]
    for task in tasks:
        files.append(f"datasets_grounding/{task}/{task}_dataset_grounding_backup.json")

    # groundingå’Œtext_groundingåˆ†å‰²æ–‡ä»¶
    splits = ["train", "test", "val"]
    qualities = ["high_quality", "low_quality"]

    for task in tasks:
        for split in splits:
            for quality in qualities:
                files.append(f"datasets_grounding/{task}/{split}_{quality}/{task}_{split}_{quality}_grounding.json")
                files.append(f"datasets_text_grounding/{task}/{split}_{quality}/{task}_{split}_{quality}_text_grounding.json")

    return files

def get_reference_image_info():
    """ä»å‚è€ƒJSONç›®å½•è·å–æ‰€æœ‰å›¾ç‰‡çš„å°ºå¯¸ä¿¡æ¯"""
    reference_images = {}

    json_dir = Path(REFERENCE_JSON_DIR)

    for json_file in json_dir.glob("*_curves.json"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if 'curves' in data and len(data['curves']) > 0:
                # ä»æ–‡ä»¶åæ¨æ–­å›¾ç‰‡å
                base_name = json_file.stem.replace('_curves', '')
                image_name = base_name + '.jpg'

                # è·å–resizeä¿¡æ¯
                resize_info = data['curves'][0].get('resize_info')
                if resize_info:
                    reference_images[image_name] = {
                        'original_size': resize_info['original_size'],
                        'smart_resize_size': resize_info['resized_size']
                    }

        except Exception as e:
            print(f"Warning: Could not parse {json_file}: {e}")

    return reference_images

def calculate_transform_scale(original_size, smart_resize_size, target_size):
    """è®¡ç®—ä»è®­ç»ƒåæ ‡åˆ°ç›®æ ‡åæ ‡çš„å˜æ¢æ¯”ä¾‹"""
    orig_w, orig_h = original_size
    smart_w, smart_h = smart_resize_size
    target_w, target_h = target_size

    # ç›´æ¥ä»è®­ç»ƒåæ ‡åˆ°ç›®æ ‡åæ ‡çš„æ¯”ä¾‹
    scale_x = target_w / smart_w
    scale_y = target_h / smart_h

    return scale_x, scale_y

def transform_bbox(bbox, scale_x, scale_y):
    """å˜æ¢bboxåæ ‡"""
    x1, y1, x2, y2 = bbox
    return [
        round(x1 * scale_x),
        round(y1 * scale_y),
        round(x2 * scale_x),
        round(y2 * scale_y)
    ]

def update_bbox_in_text(text, scale_x, scale_y):
    """åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾å¹¶æ›´æ–°æ‰€æœ‰bbox_2dåæ ‡"""
    # æŸ¥æ‰¾æ‰€æœ‰bbox_2dæ¨¡å¼
    bbox_patterns = [
        r'\"bbox_2d\":\s*\[(\d+),\s*(\d+),\s*(\d+),\s*(\d+)\]',  # æ ‡å‡†æ ¼å¼
        r'\\\"bbox_2d\\\":\s*\[(\d+),\s*(\d+),\s*(\d+),\s*(\d+)\]',  # è½¬ä¹‰æ ¼å¼
    ]

    updated_text = text
    total_replacements = 0

    for pattern in bbox_patterns:
        def replace_bbox(match):
            nonlocal total_replacements
            x1, y1, x2, y2 = map(int, match.groups())
            new_bbox = transform_bbox([x1, y1, x2, y2], scale_x, scale_y)
            total_replacements += 1

            # ä¿æŒåŸæ ¼å¼ï¼ˆæ˜¯å¦è½¬ä¹‰ï¼‰
            if '\\\"' in match.group(0):
                return f'\\\"bbox_2d\\\": [{new_bbox[0]}, {new_bbox[1]}, {new_bbox[2]}, {new_bbox[3]}]'
            else:
                return f'\"bbox_2d\": [{new_bbox[0]}, {new_bbox[1]}, {new_bbox[2]}, {new_bbox[3]}]'

        updated_text = re.sub(pattern, replace_bbox, updated_text)

    return updated_text, total_replacements

def process_json_file(file_path, image_transforms):
    """å¤„ç†å•ä¸ªJSONæ–‡ä»¶ï¼Œæ›´æ–°å…¶ä¸­çš„bboxåæ ‡"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        original_content = content
        total_replacements = 0
        processed_images = set()

        # æŒ‰å›¾ç‰‡å¤„ç†
        lines = content.split('\n')
        current_image = None

        for i, line in enumerate(lines):
            # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡è¡Œ
            image_match = re.search(r'"image":\s*"([^"]*([^/\\]+\.jpg))"', line)
            if image_match:
                image_path = image_match.group(1)
                current_image = Path(image_path).name
                continue

            # å¦‚æœå½“å‰æœ‰å›¾ç‰‡ä¸Šä¸‹æ–‡ä¸”è¯¥å›¾ç‰‡éœ€è¦å˜æ¢
            if current_image and current_image in image_transforms:
                if 'bbox_2d' in line:
                    scale_x, scale_y = image_transforms[current_image]
                    updated_line, replacements = update_bbox_in_text(line, scale_x, scale_y)

                    if replacements > 0:
                        lines[i] = updated_line
                        total_replacements += replacements
                        processed_images.add(current_image)

        # é‡æ–°ç»„åˆå†…å®¹
        updated_content = '\n'.join(lines)

        # åªæœ‰åœ¨æœ‰å˜åŒ–æ—¶æ‰å†™å…¥æ–‡ä»¶
        if updated_content != original_content:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(updated_content)

            return True, total_replacements, len(processed_images)
        else:
            return False, 0, 0

    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return False, 0, 0

def resize_image(image_path, target_size):
    """å°†å›¾ç‰‡resizeåˆ°ç›®æ ‡å°ºå¯¸"""
    try:
        with Image.open(image_path) as img:
            # ç›´æ¥resizeåˆ°ç›®æ ‡å°ºå¯¸
            resized_img = img.resize(target_size, Image.Resampling.LANCZOS)
            resized_img.save(image_path)
            return True
    except Exception as e:
        print(f"Error resizing {image_path}: {e}")
        return False

def main():
    print("=" * 80)
    print("æ‰¹é‡å›¾ç‰‡resizeå’Œåæ ‡æ›´æ–°")
    print("=" * 80)

    # 1. è·å–å‚è€ƒå›¾ç‰‡ä¿¡æ¯
    print("ğŸ“Š Step 1: è·å–å‚è€ƒå›¾ç‰‡å°ºå¯¸ä¿¡æ¯...")
    reference_images = get_reference_image_info()
    print(f"   æ‰¾åˆ° {len(reference_images)} å¼ å›¾ç‰‡çš„å°ºå¯¸ä¿¡æ¯")

    # 2. è®¡ç®—å˜æ¢çŸ©é˜µ
    print("\nğŸ“Š Step 2: è®¡ç®—å˜æ¢çŸ©é˜µ...")
    image_transforms = {}

    for image_name, info in reference_images.items():
        original_size = info['original_size']
        smart_resize_size = info['smart_resize_size']
        scale_x, scale_y = calculate_transform_scale(original_size, smart_resize_size, TARGET_SIZE)
        image_transforms[image_name] = (scale_x, scale_y)

    print(f"   è®¡ç®—äº† {len(image_transforms)} å¼ å›¾ç‰‡çš„å˜æ¢çŸ©é˜µ")

    # 3. æ›´æ–°JSONæ–‡ä»¶
    print("\nğŸ“Š Step 3: æ›´æ–°JSONæ–‡ä»¶ä¸­çš„bboxåæ ‡...")
    bbox_json_files = get_all_bbox_json_files()

    total_files_updated = 0
    total_bbox_updated = 0
    total_images_processed = 0

    for json_file in bbox_json_files:
        file_path = Path(DATA_ROOT) / json_file
        if file_path.exists():
            updated, bbox_count, image_count = process_json_file(str(file_path), image_transforms)
            if updated:
                total_files_updated += 1
                total_bbox_updated += bbox_count
                total_images_processed += image_count
                print(f"   âœ“ {json_file}: {bbox_count} bbox, {image_count} å›¾ç‰‡")
            else:
                print(f"   - {json_file}: æ— éœ€æ›´æ–°")
        else:
            print(f"   âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")

    print(f"\n   æ€»è®¡: {total_files_updated} æ–‡ä»¶æ›´æ–°, {total_bbox_updated} bboxå˜æ¢, {total_images_processed} å›¾ç‰‡å¤„ç†")

    # 4. Resizeå›¾ç‰‡
    print(f"\nğŸ“Š Step 4: Resizeå›¾ç‰‡åˆ° {TARGET_SIZE[0]}x{TARGET_SIZE[1]}...")

    # æ”¶é›†æ‰€æœ‰å›¾ç‰‡è·¯å¾„
    image_dirs = [
        "images/train/high_quality",
        "images/train/low_quality",
        "images/test/high_quality",
        "images/test/low_quality",
        "images/val/high_quality",
        "images/val/low_quality"
    ]

    total_images_resized = 0
    total_images_found = 0

    for img_dir in image_dirs:
        dir_path = Path(DATA_ROOT) / img_dir
        if dir_path.exists():
            for img_file in dir_path.glob("*.jpg"):
                total_images_found += 1
                if resize_image(str(img_file), TARGET_SIZE):
                    total_images_resized += 1
                    if total_images_resized % 50 == 0:
                        print(f"   å·²å¤„ç† {total_images_resized} å¼ å›¾ç‰‡...")

    print(f"   æ€»è®¡: {total_images_resized}/{total_images_found} å¼ å›¾ç‰‡resizeæˆåŠŸ")

    # 5. æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š å¤„ç†å®Œæˆæ€»ç»“:")
    print("=" * 80)
    print(f"âœ… JSONæ–‡ä»¶æ›´æ–°: {total_files_updated} ä¸ªæ–‡ä»¶")
    print(f"âœ… åæ ‡å˜æ¢: {total_bbox_updated} ä¸ªbbox")
    print(f"âœ… å›¾ç‰‡resize: {total_images_resized} å¼ å›¾ç‰‡")
    print(f"âœ… ç›®æ ‡å°ºå¯¸: {TARGET_SIZE[0]}Ã—{TARGET_SIZE[1]}")
    print("=" * 80)

if __name__ == "__main__":
    main()